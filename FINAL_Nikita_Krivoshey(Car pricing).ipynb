{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Внимание!!! Важно, что бы файлы с данными и исполняемый файл находились в одной папке, \n",
    "# тогда пути к тестовым и тренировочным наборам будут содержать только имена файлов.\n",
    "# \n",
    "# В пути к тренировочным и тестовым данным запрежается использовать абсалютную адресацию, \n",
    "# то есть адресацию, в которой присутствуют имена папок. Путь должен содержать только имя файла.\n",
    "#\n",
    "# Напоминание: под моделью машинного обучения понимаются все действия с исходными данными, \n",
    "# которые необходимо произвести, что бы сопоставить признаки целевому значению.\n",
    "#\n",
    "#\n",
    "# ПОДБОР ПАРАМЕТРОВ В ОТДЕЛЬНЫХ ФАЙЛАХ, важно там сохранять ramdom_seed для повторимости результата\n",
    "# данные файлы обязательны к размещению в репозитории\n",
    "##\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данный блок предназначен только для подключения необходимых библиотек\n",
    "# запрещается подключать библиотеки в других блоках\n",
    "#\n",
    "# установка дополнительных библиотек размещается прямо здесь (обязательно закоментированы)\n",
    "#\n",
    "# pip install\n",
    "#pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV , cross_val_score , RandomizedSearchCV,KFold,RepeatedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder , LabelEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import get_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_percentage_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import shap\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection  import RFE\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm \n",
    "from sklearn.svm import LinearSVC\n",
    "from itertools import product\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и выполнение лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В области находится одна, единственная, итоговая модель машинного обучения с однозначными, \n",
    "# зафиксированными параметрами\n",
    "#\n",
    "# В данной области категорически запрещается искать, выбирать, улучшать, оптимизировать, \n",
    "# тюниговать и т.д. модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к тренировочному набору\n",
    "path_train = 'train.csv' # содержит только имя файла, без имен папок\n",
    "df = pd.read_csv(path_train)\n",
    "display(df.head())\n",
    "# Путь к тестовому набору\n",
    "path_test  = 'test.csv' # содержит только имя файла, без имен папок\n",
    "df1 = pd.read_csv(path_test)\n",
    "display(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#все манипуляции есть подробно в файлах Block 2, Model, Features, поэтому тут я все сделаю в одном блоке\n",
    "# чтобы не размножать много ячеек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])\n",
    "# Функции для обработки колонок с буквами, а также для их разделения\n",
    "def volume(s):\n",
    "    if len(s) <= 3:\n",
    "        a = s\n",
    "    else:\n",
    "        a = s[:3]\n",
    "    return a;\n",
    "\n",
    "def turbo(df):\n",
    "    b = []\n",
    "    for i in range(len(df)):\n",
    "        if df['Engine_volume'][i][4:] == 'Turbo':\n",
    "            b.append(1)    \n",
    "        else:\n",
    "            b.append(0)\n",
    "    return pd.Series(b);\n",
    "# Делаю новую колонку Турбо, чтобы выделять машины с турбированным двигателем\n",
    "# а также разделяю пробег от километров и делаю из этого целые числа\n",
    "df['Turbo'] = 0\n",
    "df['Turbo'] = turbo(df)\n",
    "df['Engine_volume'] = [volume(i) for i in df['Engine_volume']]\n",
    "df['Engine_volume'] = df['Engine_volume'].astype(float)\n",
    "df.Mileage = [int(''.join(filter(str.isdigit, i ))) for i in df.Mileage]\n",
    "\n",
    "# Ниже буду выбрасывать выброс, которые нашел по графикам\n",
    "ind = df[df['Engine_volume'] == 0].index\n",
    "# это некорректные данные, поэтому удаляем их\n",
    "df = df.drop(index=ind)\n",
    "inde = df[df['Engine_volume'] == 20].index\n",
    "df = df.drop(index=inde)\n",
    "df.Mileage.nlargest(15)\n",
    "# если загуглить, то можно увидеть, что можно прочитать\n",
    "# Книги рекордов Гиннеса цифра – 3,2 миллиона миль (5 149 900 км) – датируется маем 2013 года.\n",
    "# логично, что все пробеги ниже этого очень большого числа подходят под условия\n",
    "# убираем это большьшое число(удаляем по индексу)\n",
    "df = df.drop(index = 3169)\n",
    "# 0 пробег у авто 2010-х годов это очень странно, что на них вообще нет пробега\n",
    "ind = df[df['Mileage'] == 0].index\n",
    "df = df.drop(index=ind)\n",
    "#display(df[df.duplicated()])\n",
    "# есть дубликаты, поэтому убираем дубликаты\n",
    "#display(df[df.duplicated()].head(60))\n",
    "df_duplicates = df.drop('Price', axis = 1)\n",
    "dupl_rows = df_duplicates[df_duplicates.duplicated()].index\n",
    "df = df.drop(index=dupl_rows)\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "# удаляем модель, тк эта переменная нам больше не нужна, есть бренд\n",
    "df = df.drop(columns=['Model'])\n",
    "#display(df[df['Year_of_production'] < 1999].Price)\n",
    "# Машина за почти за 50000 1995 года будет довольно сильно колебать мое обучение, поэтому считаю выбросом \n",
    "# и выбрасываю ее\n",
    "df = df.drop(index=7146)\n",
    "df = df[df['Year_of_production'] > 1965]\n",
    "\n",
    "# убираю неинформативные переменных, которые отобрал в файле Features\n",
    "df = df.drop(columns=['Doors','Cylinders','Leather_interior'])\n",
    "# надо убрать ненужные преобразования в трансформере и оформить все к test тоже\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# я это расписывал в файле Block2 и features, что сделаю заранее преобразование столбцов (пробег и налоги)\n",
    "# возьму преобразование Бокса-Кокса для пробег и налога\n",
    "# преобраазуем переменные пробег и налог\n",
    "power = PowerTransformer(method='box-cox') \n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "mile = power.fit_transform(minmax.fit_transform(pd.DataFrame(df.Mileage)) + 1)\n",
    "tax = power.fit_transform(minmax.fit_transform(pd.DataFrame(df.Tax)) + 1)\n",
    "\n",
    "\n",
    "df.Mileage = mile\n",
    "df.Tax = tax\n",
    "#преобразовываю данные и записываю в колонки моего Х после трансформера\n",
    "# скорее всего это преобразование буду делать до трансформера,то есть сразу преобразовывать фрейм по этим колонкам\n",
    "# тк трудно будет сделать преобразования после pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Brand','Type','Color']\n",
    "num_features = ['Year_of_production','Mileage','Tax']\n",
    "y = np.array(df.Price)\n",
    "X = df.drop(columns=['Price'])\n",
    "columns = ['Brand','Type','Color','Fuel_type','Gear_box','Drive_wheels','Year_of_production','Mileage','Tax','Engine_volume','Airbags','Turbo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_type_map = [{\n",
    "    'col':'Fuel_type', \n",
    "    'mapping':{'Diesel':3,'Petrol':2,'Hybrid':1,'LPG':0}\n",
    "    }]\n",
    "gear_box_map = [{\n",
    "    'col':'Gear_box',\n",
    "    'mapping':{'Tiptronic':3,'Automatic':2,'Variator':1,'Manual':0}\n",
    "    }]\n",
    "drive_wheels_map = [{\n",
    "    'col':'Drive_wheels',\n",
    "    'mapping':{'4x4':2,'Rear':1,'Front':0}\n",
    "    }]\n",
    "\n",
    "fuel_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = fuel_type_map))])\n",
    "\n",
    "gear_box_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = gear_box_map))])\n",
    "\n",
    "drive_wheels_transformer = Pipeline(steps=[\n",
    "    ('ce',ce.OrdinalEncoder(mapping = drive_wheels_map))])\n",
    "\n",
    "   \n",
    "# для деревьев можно не стандартизировать данные в фичах \n",
    "CT = ColumnTransformer(transformers=[('cat',OrdinalEncoder(),cat_features),\n",
    "                                     ('fuel_type', fuel_transformer, ['Fuel_type']),\n",
    "                                     ('gear_box', gear_box_transformer, ['Gear_box']),\n",
    "                                     ('drive_wheels', drive_wheels_transformer, ['Drive_wheels']),\n",
    "                                     ('num','passthrough',num_features)],\n",
    "                                      remainder = 'passthrough')\n",
    "\n",
    "display(CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#все манипуляции есть подробно в файле Test_processing поэтому тут я все сделаю в одном блоке\n",
    "# чтобы не размножать много ячеек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns=['ID'])\n",
    "# Функции для обработки колонок с буквами, а также для их разделения\n",
    "def volume(s):\n",
    "    if len(s) <= 3:\n",
    "        a = s\n",
    "    else:\n",
    "        a = s[:3]\n",
    "    return a;\n",
    "\n",
    "def turbo(df):\n",
    "    b = []\n",
    "    for i in range(len(df)):\n",
    "        if df['Engine_volume'][i][4:] == 'Turbo':\n",
    "            b.append(1)    \n",
    "        else:\n",
    "            b.append(0)\n",
    "    return pd.Series(b);\n",
    "# Делаю новую колонку Турбо, чтобы выделять машины с турбированным двигателем\n",
    "# а также разделяю пробег от километров и делаю из этого целые числа\n",
    "df1['Turbo'] = 0\n",
    "df1['Turbo'] = turbo(df1)\n",
    "df1['Engine_volume'] = [volume(i) for i in df1['Engine_volume']]\n",
    "df1['Engine_volume'] = df1['Engine_volume'].astype(float)\n",
    "df1.Mileage = [int(''.join(filter(str.isdigit, i ))) for i in df1.Mileage]\n",
    "# Посмотрим теперь на 0 и 20л двигатели\n",
    "#display(df1[df1['Engine_volume'] == 0])\n",
    "# Объем двигателя Тойота Аква составляет 1.5 л. Мощность двигателей Toyota Aqua от 74 до 91 л.\n",
    "#\n",
    "#Автомобиль комплектовался моторами объёмом: 1.6, 2.0, 2.4 л.\n",
    "#display(df1[df1['Engine_volume'] == 20])\n",
    "# То есть это тоже неккоретные данные,которые мы можем убрать\n",
    "ind1 = df1[df1['Engine_volume'] == 0].index\n",
    "df1 = df1.drop(index=ind1)\n",
    "inde1 = df1[df1['Engine_volume'] == 20].index\n",
    "df1 = df1.drop(index=inde1)\n",
    "# теперь посмотрим на дубликаты и уберем их, тк есть полностью одинаковые машины, но по цене разной - странно\n",
    "# цена разная с дубликатами - находил в траин\n",
    "df1_duplicates = df1.copy()\n",
    "dupl_rows1 = df1_duplicates[df1_duplicates.duplicated()].index\n",
    "df1 = df1.drop(index=dupl_rows1)\n",
    "df1 = df1.drop_duplicates(keep = 'first')\n",
    "#display(df1[df1.Mileage==0]) # тоже вот очень странно(машинам по 10 и более лет некоторым, а у них 0 пробег)\n",
    "# я думаю, что это тоже ошибки в данных, поэтому удаляю\n",
    "ii1 = df1[df1.Mileage==0].index\n",
    "df1 = df1.drop(index=ii1)\n",
    "# посмотрим как отмечал выше на 0 и 20л двигатель\n",
    "#display(df1[df1['Engine_volume'] == 0])\n",
    "#display(df1[df1['Engine_volume'] == 20])\n",
    "# это тоже является некорректными данными, которые не соответствуют действительности\n",
    "## Объем двигателя Тойота Аква составляет 1.5 л. Мощность двигателей Toyota Aqua от 74 до 91 л.\n",
    "##Автомобиль комплектовался моторами объёмом: 1.6, 2.0, 2.4 л.(Соната)\n",
    "#удаляем\n",
    "i1 = df1[df1['Engine_volume'] == 0].index\n",
    "df1 = df1.drop(index=i1)\n",
    "\n",
    "iii1 = df1[df1['Engine_volume'] == 20].index\n",
    "df1 = df1.drop(index=iii1)\n",
    "df1 = df1.drop(columns=['Model'])\n",
    "df1 = df1.drop(columns=['Doors','Cylinders','Leather_interior'])\n",
    "display(df1.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# я это расписывал в файле Block2 и features, что сделаю заранее преобразование столбцов (пробег и налоги)\n",
    "# возьму преобразование Бокса-Кокса для пробег и налога\n",
    "# преобраазуем переменные пробег и налог\n",
    "powerr = PowerTransformer(method='box-cox') \n",
    "minmaxx = MinMaxScaler()\n",
    "\n",
    "milee = powerr.fit_transform(minmaxx.fit_transform(pd.DataFrame(df1.Mileage)) + 1)\n",
    "taxx = powerr.fit_transform(minmaxx.fit_transform(pd.DataFrame(df1.Tax)) + 1)\n",
    "\n",
    "\n",
    "df1.Mileage = milee\n",
    "df1.Tax = taxx\n",
    "#преобразовываю данные и записываю в колонки моего Х после трансформера\n",
    "# скорее всего это преобразование буду делать до трансформера,то есть сразу преобразовывать фрейм по этим колонкам\n",
    "# тк трудно будет сделать преобразования после pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем маску\n",
    "mask = df1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок(и) обучения и поверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_pipe =  Pipeline([\n",
    "            ('preprocessing', CT), \n",
    "            ('estimator',RandomForestRegressor(n_estimators=3500))\n",
    "            ])\n",
    "\n",
    "finish_pipe.fit(X, y)\n",
    "y_pred = finish_pipe.predict(X)\n",
    "print('R2',r2_score(y,y_pred))\n",
    "print('MSE', mean_squared_error(y,y_pred))\n",
    "print('MAPE',mean_absolute_percentage_error(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок предсказания с использованием тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = finish_pipe.predict(df1)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Маска отобраных номеров строк для предсказания из тестового набора\n",
    "mask = mask\n",
    "\n",
    "# Название вектора предсказанных значений  y_predict полученого на основании тестового набора\n",
    "y_predict = y_predict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "acc0dcb458adea865fa90ce4f43fb3956ae49c60606d0d549bfdeff9ec2bcd00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
